{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22681d3c-c074-41cb-9f2f-12a4ee7c7eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18f5ba99-4ed5-4bc7-aa49-81bc5ed71281",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39549d2a-57e9-437b-9189-4717c6c0a4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_client = OpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc9e70dc-0c27-4329-bebe-8cbe7bc1b9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The Starry Night of Luna the Unicorn**\n",
      "\n",
      "Once upon a time, in a magical forest filled with sparkling rivers and towering trees, lived a gentle unicorn named Luna. Her coat shimmered like the moonlight, and her mane flowed with colors of the rainbow. Every night, Luna would wander through the forest, spreading joy and light wherever she went.\n",
      "\n",
      "One evening, as Luna grazed near a glistening pond, she noticed the sky turn a deep shade of purple. Suddenly, she saw a shooting star streak across the heavens. Luna's heart raced. \"I wish to find the legendary Starflower,\" she whispered. It was said that the Starflower could grant one special wish.\n",
      "\n",
      "Determined, Luna followed the twinkle of the stars that seemed to beckon her. She galloped through the moonlit forest, her hooves barely touching the ground, as fireflies danced around her like tiny lanterns.\n",
      "\n",
      "After a while, Luna reached the foot of the Whispering Mountains, where the first rays of dawn began to paint the sky. There, at the top, was the Starflower, glowing softly under the fading stars. But as she climbed, dark clouds rolled in, and a gust of wind threatened to sweep her away.\n",
      "\n",
      "But Luna remembered her wish. Gathering all her courage, she whispered the magic words: \"With kindness and love, I rise above.\" Suddenly, a warm light enveloped her, and the clouds began to part. With newfound strength, she soared up the mountain, her heart shining brighter than the morning sun.\n",
      "\n",
      "At the peak, Luna found the Starflower, its petals sparkling like diamonds. She leaned down and made her wish: ‚ÄúI wish for happiness for all the creatures in the forest.‚Äù The Starflower glowed and bloomed more beautifully than ever before, sending sparkles of light across the valley.\n",
      "\n",
      "From that day on, Luna became known as the Guardian of Joy, and every night, she returned to the starry sky, sharing her light and laughter with all her friends in the forest. And when you looked up on a clear night, you could always see a shooting star, a reminder of Luna and her magical adventure.\n",
      "\n",
      "With a heart full of dreams and starlight, Luna lay beneath a great oak tree, closed her eyes, and drifted into a peaceful sleep, knowing that her wish had spread happiness to all.\n",
      "\n",
      "And as she slept, the stars twinkled brighter, as if whispering sweet dreams to every creature in the forest.\n",
      "\n",
      "**The End**\n"
     ]
    }
   ],
   "source": [
    "response = openai_client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=\"Write a short bedtime story about a unicorn.\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed44d718-3f26-4aad-bf98-2b49335f4cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The Moonlit Meadow**\n",
      "\n",
      "Once upon a time, in a quiet valley where the grass grew soft and silver under the night sky, there lived a gentle unicorn named Liora. Her coat shimmered like fresh snow, and her horn glowed with a warm, amber light that made the flowers around her sparkle.\n",
      "\n",
      "Every evening, after the sun had dipped below the hills, Liora would trot through the meadow, her hooves making a tiny, rhythmic thump that sounded like a lullaby. The wind whispered through the leaves, and the fireflies twinkled, as if they were tiny lanterns waiting to be lit.\n",
      "\n",
      "One night, Liora noticed a little rabbit, trembling beside a fallen oak. ‚ÄúWhat‚Äôs wrong, little friend?‚Äù she asked, her voice as soft as a sigh.\n",
      "\n",
      "The rabbit shook his head. ‚ÄúI lost my way home,‚Äù he sniffed. ‚ÄúI can‚Äôt see the path in the dark, and I‚Äôm so cold.‚Äù\n",
      "\n",
      "Liora nudged her horn toward the rabbit and let out a gentle glow. The light danced on the ground, painting a glowing path that shone like a silver ribbon. ‚ÄúFollow me,‚Äù Liora said. ‚ÄúI‚Äôll guide you safely back.‚Äù\n",
      "\n",
      "The rabbit hopped beside her, feeling the warmth spread through his whiskers. The meadow seemed to hum a calm song as they walked. Liora‚Äôs horn grew brighter with each step, turning the darkness into a cozy, silver-lit trail.\n",
      "\n",
      "When they reached the rabbit‚Äôs burrow, a little family of rabbits welcomed him back with happy hisses and soft nuzzles. ‚ÄúThank you, Liora,‚Äù the mother rabbit said. ‚ÄúYou brought back the light when we needed it most.‚Äù\n",
      "\n",
      "Liora bowed her head, her eyes twinkling. ‚ÄúWe all need a little light when the night feels dark,‚Äù she replied. ‚ÄúAnd sometimes, a friend can bring that light.‚Äù\n",
      "\n",
      "With a gentle nod, Liora turned toward the sky. The moon rose higher, its pale light bathing the meadow. She let out a soft, melodic sigh that sounded like the wind‚Äôs sighing lullaby. The valley fell into a peaceful hush, and the stars began to twinkle like tiny wishes.\n",
      "\n",
      "As Liora stood on the meadow‚Äôs edge, she felt the night wrap around her like a warm blanket. She knew that no matter how far the shadows stretched, a little kindness, a gentle glow, and a caring heart could guide anyone back to where they belong.\n",
      "\n",
      "With that thought, Liora closed her eyes, and the meadow, the rabbit, the moon, and the stars all fell into a sweet, gentle sleep. üåô‚ú®\n",
      "\n",
      "And so, under the glow of the silver meadow, everyone slept peacefully, dreaming of the night when a unicorn‚Äôs kindness turned darkness into light. \n",
      "\n",
      "**The End.**\n"
     ]
    }
   ],
   "source": [
    "response = groq_client.responses.create(\n",
    "    model=\"openai/gpt-oss-20b\",\n",
    "    input=\"Write a short bedtime story about a unicorn.\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48367588-e5b7-4c6e-8885-266850cbb77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "597612d3-fadb-4fe3-b3d5-3702d10b0f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'The zoom link is only published to instructors/presenters/TAs.\\nStudents participate via Youtube Live and submit questions to Slido (link would be pinned in the chat when Alexey goes Live). The video URL should be posted in the announcements channel on Telegram & Slack before it begins. Also, you will see it live on the DataTalksClub YouTube Channel.\\nDon‚Äôt post your questions in chat as it would be off-screen before the instructors/moderators have a chance to answer it if the room is very active.',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Office Hours - What is the video/zoom link to the stream for the ‚ÄúOffice Hour‚Äù or workshop sessions?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16e62cf-e8eb-4671-aeab-facda0364063",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d834889-b977-4cd1-b159-c9464d9181fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minsearch import AppendableIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d542bd2f-f99f-4e5b-bd31-bd4d7748978a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.append.AppendableIndex at 0x72b9c18ead20>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = AppendableIndex(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ed68a1-71f1-4b18-b05b-0c298339bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "\n",
    "def search(query: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Search the index for documents matching the given query.\n",
    "\n",
    "    This function queries the index with a fixed course filter and \n",
    "    predefined boost weights for specific fields.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query string.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: A list of search result objects returned \n",
    "        by `index.search()`. Each result is represented as a dictionary.\n",
    "    \"\"\"\n",
    "    boost: Dict[str, float] = {\"question\": 3.0, \"section\": 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={\"course\": \"data-engineering-zoomcamp\"},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def add_entry(question: str, answer: str) -> None:\n",
    "    \"\"\"\n",
    "    Add a new question‚Äìanswer entry to the index.\n",
    "\n",
    "    This function constructs a document with the provided question\n",
    "    and answer, tags it as user-added, and appends it to the index\n",
    "    under the 'data-engineering-zoomcamp' course.\n",
    "\n",
    "    Args:\n",
    "        question (str): The question text to store.\n",
    "        answer (str): The corresponding answer text.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    doc = {\n",
    "        'question': question,\n",
    "        'text': answer,\n",
    "        'section': 'user added',\n",
    "        'course': 'data-engineering-zoomcamp'\n",
    "    }\n",
    "    index.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5370738e-2ea6-41b2-8668-5da1826d4f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"search\",\n",
    "    \"description\": \"Search the FAQ database\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Search query text to look up in the course FAQ.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10fe4ea7-d596-4e90-bfc8-936183f95b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = search(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a40905c-4eb5-4c48-847d-b743148a53ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6939270f-2220-44fd-bbc3-4d935ecb0456",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'I just discovered the course. Can I join it now?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7ff5dcc-a7de-4c59-9465-07d20eea2c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Answer the question from the student using the provided context\n",
    "\n",
    "<QUESTION>{question}</QUESTION>\n",
    "\n",
    "<CONTEXT>{json.dumps(result)}</CONTEXT>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391851f4-5af4-456a-b050-d6c6c0bf3266",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "search \n",
    "\n",
    "- hitrate\n",
    "- MRR\n",
    "- NDCG \n",
    "\n",
    "\n",
    "Agent\n",
    "\n",
    "- judges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eea7b9-9e0a-4f91-b6df-ed7f1ddca413",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_instructions = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "For each question, perfrom at least 3 searches to make sure you explore the topic deep enough.\n",
    "\n",
    "\n",
    "\"\"\".strip()\n",
    "\n",
    "# agentic RAG\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": agent_instructions},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "response = openai_client.responses.create(\n",
    "    model=\"gpt-5-nano\", #\"gpt-4o-mini\",\n",
    "    input=chat_messages,\n",
    "    tools=[search_tool]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "23957a0e-8f1c-40fb-97c9-f6133012c72b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 528)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage.input_tokens, response.usage.output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5e1457-e0b8-4a7e-99de-1921776f558f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#$0.050, $0.400 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0380064-9526-444c-acfe-903c9c97256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install genai-prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ceeb679d-abf9-44ed-b57d-22c5620eb23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from genai_prices import Usage, calc_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b92282a0-9a84-41b4-b012-29979217227b",
   "metadata": {},
   "outputs": [],
   "source": [
    "price = calc_price(\n",
    "    Usage(input_tokens=37, output_tokens=528),\n",
    "    model_ref='gpt-5-nano',\n",
    "    provider_id='openai'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c4d3584e-47c3-4e5b-93e0-9fe117df3fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decimal('0.00021305')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price.total_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc095a20-2b7d-4ba6-ac15-66edab3324da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseFunctionToolCall(arguments='{\"query\":\"Can I join the course now?\"}', call_id='call_plxceNhVOrmUQC7gFD11ZDXb', name='search', type='function_call', id='fc_02a0dec5722556bc006925720835408197b73dca4d6adc1af8', status='completed')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = response.output[0]\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cccb7c3e-a1e6-4470-9c99-8e372b805539",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_messages.append(tool_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f0b04371-062d-44c3-be79-59a2b5ac6fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result = search(query=\"Can I join the course now?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba3e183-b217-4b81-aa8e-c5517a60fea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "06ddb7e5-3b9e-4370-9356-d57e68d78484",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_json = json.dumps(search_result, indent=2)\n",
    "\n",
    "chat_messages.append({\n",
    "    \"type\": \"function_call_output\",\n",
    "    \"call_id\": tool_call.call_id,\n",
    "    \"output\": result_json,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c24e59a3-5b26-4099-9f31-4828002a112a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'I just discovered the course. Can I join it now?'},\n",
       " ResponseFunctionToolCall(arguments='{\"query\":\"Can I join the course now?\"}', call_id='call_plxceNhVOrmUQC7gFD11ZDXb', name='search', type='function_call', id='fc_02a0dec5722556bc006925720835408197b73dca4d6adc1af8', status='completed'),\n",
       " {'type': 'function_call_output',\n",
       "  'call_id': 'call_plxceNhVOrmUQC7gFD11ZDXb',\n",
       "  'output': '[\\n  {\\n    \"text\": \"Yes, even if you don\\'t register, you\\'re still eligible to submit the homeworks.\\\\nBe aware, however, that there will be deadlines for turning in the final projects. So don\\'t leave everything for the last minute.\",\\n    \"section\": \"General course-related questions\",\\n    \"question\": \"Course - Can I still join the course after the start date?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"No, you can only get a certificate if you finish the course with a \\\\u201clive\\\\u201d cohort. We don\\'t award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\",\\n    \"section\": \"General course-related questions\",\\n    \"question\": \"Certificate - Can I follow the course in a self-paced mode and get a certificate?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\",\\n    \"section\": \"General course-related questions\",\\n    \"question\": \"Course - Can I follow the course after it finishes?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"The purpose of this document is to capture frequently asked technical questions\\\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  \\\\u201cOffice Hours\\'\\' live.1\\\\nSubscribe to course public Google Calendar (it works from Desktop only).\\\\nRegister before the course starts using this link.\\\\nJoin the course Telegram channel with announcements.\\\\nDon\\\\u2019t forget to register in DataTalks.Club\\'s Slack and join the channel.\",\\n    \"section\": \"General course-related questions\",\\n    \"question\": \"Course - When will the course start?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  },\\n  {\\n    \"text\": \"You don\\'t need it. You\\'re accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\",\\n    \"section\": \"General course-related questions\",\\n    \"question\": \"Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?\",\\n    \"course\": \"data-engineering-zoomcamp\"\\n  }\\n]'}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8534456-680a-4208-9d47-666535023c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai_client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=chat_messages,\n",
    "    tools=[search_tool]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "744b2a70-846a-48b1-bbc7-86f3db600cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, you can still join the course, even if you haven't registered. You're eligible to submit homework, but keep in mind that there are deadlines for the final projects, so it's best not to leave everything until the last minute.\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "58d2395f-ef22-4698-ba7b-26b8d6b86c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_messages.append(\n",
    "    {\"role\": \"user\", \"content\": \"but are you sure I can get my certificate?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f0fa4772-7993-4a3b-a624-5ee8a51592cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You can only receive a certificate if you complete the course with a \"live\" cohort. Certificates are not awarded for self-paced mode since you need to peer-review projects during the course. Make sure to join when the course is running to be eligible for the certificate!'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai_client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=chat_messages,\n",
    "    tools=[search_tool]\n",
    ")\n",
    "response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dc7bfc6c-72e0-4e97-9090-0d2bbbe631b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_messages = [\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "response = groq_client.responses.create(\n",
    "    model=\"openai/gpt-oss-20b\",\n",
    "    input=chat_messages,\n",
    "    tools=[search_tool]\n",
    ")\n",
    "response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7aba4bcd-3402-4176-866a-9d1f00df20e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseReasoningItem(id='resp_01kax4ttzkf2r8qchrj6hebrnc', summary=[], type='reasoning', content=[Content(text='We need to respond. Likely the user asks if they can join a course they discovered now. We may need to check FAQ. Let\\'s search FAQ: query \"join course after discovered\".', type='reasoning_text')], encrypted_content=None, status='completed'),\n",
       " ResponseFunctionToolCall(arguments='{\"query\":\"join course after discovered\"}', call_id='fc_3e88e870-3186-4302-a243-e8134aa281af', name='search', type='function_call', id='fc_3e88e870-3186-4302-a243-e8134aa281af', status='completed')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5de8b1a-0c98-444f-ac7e-7458f57e67f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "536e24a2-5437-4c7c-9517-39ca00a93a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "532b0321-5588-407a-ab8b-7ae57c6f4537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_call(call):\n",
    "    args = json.loads(call.arguments)\n",
    "    f_name = call.name\n",
    "    f = globals()[f_name]\n",
    "    result = f(**args)\n",
    "    result_json = json.dumps(result, indent=2)\n",
    "    return {\n",
    "        \"type\": \"function_call_output\",\n",
    "        \"call_id\": call.call_id,\n",
    "        \"output\": result_json,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232bfa6f-223a-44b0-84a6-6440b0311cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0cf2ae73-9f2f-424f-b87a-e4e45c7a5ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'I just discovered the course. Can I join it now?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "087d79b2-e4ee-483e-a976-7cecfc7ce5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_instructions = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "If you want to look up the answer, explain why before making the call. Use as many \n",
    "keywords from the user question as possible when making first requests.\n",
    "\n",
    "Make multiple searches (up to 3).\n",
    "\n",
    "At the end, make a clarifying question based on what you presented and ask if there are \n",
    "other areas that the user wants to explore.\n",
    "\"\"\".strip()\n",
    "\n",
    "# agentic RAG\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d454f343-2dac-4989-a612-bbaa2ecfd5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of requests 1\n",
      "To answer accurately, I'll quickly check our course FAQ for policies on joining mid-session, late enrollment options, and how to enroll. I'll run a few searches using keywords from your question to surface the relevant guidance.\n",
      "search {'query': 'Can I join the course now enrollment open late enrollment policy how to enroll'}\n",
      "number of requests 2\n",
      "Great question ‚Äî yes, you can join now. Our course FAQ indicates that you can join after the start date and still participate. Specifically:\n",
      "- You‚Äôre eligible to submit homeworks even if you join after the start date.\n",
      "- If you want a certificate, you‚Äôll need to participate in a live cohort (self-paced mode does not award certificates).\n",
      "- You‚Äôll have access to course materials after it finishes, and you can keep working toward the final capstone project.\n",
      "- The Slack channel remains open for questions.\n",
      "\n",
      "If you‚Äôd like, I can pull the exact enrollment link for the current cohort or help you compare live cohorts vs. self-paced options (including deadlines and certificate eligibility).\n",
      "\n",
      "Would you like me to fetch the enrollment link for you, or would you prefer to explore live vs. self-paced options first? Also, are there any other areas you want to explore (deadlines, prerequisites, or how the final project works)?\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": agent_instructions},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "while True: # agentic loop / tool call loop\n",
    "    response = openai_client.responses.create(\n",
    "        model=\"gpt-5-nano\",#\"gpt-4o-mini\",\n",
    "        input=chat_messages,\n",
    "        tools=[search_tool]\n",
    "    )\n",
    "    cnt = cnt + 1\n",
    "    print('number of requests', cnt)\n",
    "\n",
    "    chat_messages.extend(response.output)\n",
    "    \n",
    "    has_function_calls = False\n",
    "    \n",
    "    for message in response.output:\n",
    "        if message.type == 'message':\n",
    "            print(message.content[0].text)\n",
    "    \n",
    "        if message.type == 'function_call':\n",
    "            arguments = json.loads(message.arguments)\n",
    "            f_name = message.name\n",
    "            print(f_name, arguments)\n",
    "            results = make_call(message)\n",
    "            chat_messages.append(results)\n",
    "    \n",
    "            has_function_calls = True\n",
    "\n",
    "    if has_function_calls == False:\n",
    "        break\n",
    "\n",
    "    if number_of_tokens > 100000:\n",
    "        chat_messages.append({'role': 'user', 'message': 'SYSTEM MESSAGE: you have reached the limit, proceed to finishing the response'}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2a0398f2-94f8-45a0-a37a-08d2e03ba487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toyaikit.llm import OpenAIClient\n",
    "from toyaikit.tools import Tools\n",
    "from toyaikit.chat import IPythonChatInterface\n",
    "from toyaikit.chat.runners import OpenAIResponsesRunner\n",
    "from toyaikit.chat.runners import DisplayingRunnerCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2f7855-6427-4e4c-bf94-a94a67072432",
   "metadata": {},
   "source": [
    "    agent_tools = Tools()\n",
    "    agent_tools.add_tool(search, search_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a7b4a392-b283-4cc9-8093-d88ffb176937",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_tools = Tools()\n",
    "agent_tools.add_tool(search)\n",
    "agent_tools.add_tool(add_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f88f0781-70af-463b-a289-250353b2d0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_interface = IPythonChatInterface()\n",
    "\n",
    "runner = OpenAIResponsesRunner(\n",
    "    tools=agent_tools,\n",
    "    developer_prompt=agent_instructions,\n",
    "    chat_interface=chat_interface,\n",
    "    llm_client=OpenAIClient(model='gpt-4o-mini')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "22d1411c-9067-4fd3-b600-0a1ef7f43094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: HOW DO I DO WELL IN MODULE 1?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Response received\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>To provide the best guidance on excelling in Module 1, I will look up the specific topics covered in that module and any recommended strategies for success. This can include study techniques, key concepts, and essential resources.</p>\n",
       "<p>Let's start by searching for specific strategies or advice related to Module 1 of the course.</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\":\"how to succeed in Module 1\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"query\":\"how to succeed in Module 1\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>[\n",
       "  {\n",
       "    \"text\": \"You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=\\u201d${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}\\u201d\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\\\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\\\"` appropriately.\\nAdditionally, you can check for the version of \\u2018py4j\\u2019 of the spark you\\u2019re using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\",\n",
       "    \"section\": \"Module 5: pyspark\",\n",
       "    \"question\": \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\",\n",
       "    \"course\": \"data-engineering-zoomcamp\"\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\",\n",
       "    \"section\": \"Module 4: analytics engineering with dbt\",\n",
       "    \"question\": \"DBT - Error: No module named 'pytz' while setting up dbt with docker\",\n",
       "    \"course\": \"data-engineering-zoomcamp\"\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex&lt;&lt;t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\\\"Murray Hill\\\") & (new_final.b_zone==\\\"Midwood\\\")).show()\\nKrishna Anand\",\n",
       "    \"section\": \"Module 5: pyspark\",\n",
       "    \"question\": \"Module Not Found Error in Jupyter Notebook .\",\n",
       "    \"course\": \"data-engineering-zoomcamp\"\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"Issue:\\ne\\u2026\\nSolution:\\npip install psycopg2-binary\\nIf you already have it, you might need to update it:\\npip install psycopg2-binary --upgrade\\nOther methods, if the above fails:\\nif you are getting the \\u201c ModuleNotFoundError: No module named 'psycopg2' \\u201c error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\nFirst uninstall the psycopg package\\nThen update conda or pip\\nThen install psycopg again using pip.\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\",\n",
       "    \"section\": \"Module 1: Docker and Terraform\",\n",
       "    \"question\": \"Postgres - ModuleNotFoundError: No module named 'psycopg2'\",\n",
       "    \"course\": \"data-engineering-zoomcamp\"\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \\\"TypeError: 'module' object is not callable\\\"\\nSolution:\\nconn_string = \\\"postgresql+psycopg://root:root@localhost:5432/ny_taxi\\\"\\nengine = create_engine(conn_string)\",\n",
       "    \"section\": \"Module 1: Docker and Terraform\",\n",
       "    \"question\": \"Python - SQLALchemy - TypeError 'module' object is not callable\",\n",
       "    \"course\": \"data-engineering-zoomcamp\"\n",
       "  }\n",
       "]</pre>\n",
       "            </div>\n",
       "\n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Response received\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\":\"success strategies Module 1 Docker an...)</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"query\":\"success strategies Module 1 Docker and Terraform\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>[\n",
       "  {\n",
       "    \"text\": \"You get this error because I run the command terraform init outside the working directory, and this is wrong.You need first to navigate to the working directory that contains terraform configuration files, and and then run the command.\",\n",
       "    \"section\": \"Module 1: Docker and Terraform\",\n",
       "    \"question\": \"Terraform - Terraform initialized in an empty directory! The directory has no Terraform configuration files. You may begin working with Terraform immediately by creating Terraform configuration files.g\",\n",
       "    \"course\": \"data-engineering-zoomcamp\"\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"The error:\\nError: googleapi: Error 403: terraform-trans-campus@trans-campus-410115.iam.gserviceaccount.com does not have storage.buckets.create access to the Google Cloud project. Permission 'storage.buckets.create' denied on resource (or it may not exist)., forbidden\\nThe solution:\\nYou have to declare the project name as your Project ID, and not your Project name, available on GCP console Dashboard.\",\n",
       "    \"section\": \"Module 1: Docker and Terraform\",\n",
       "    \"question\": \"Terraform - Error creating Bucket: googleapi: Error 403: Permission denied to access \\u2018storage.buckets.create\\u2019\",\n",
       "    \"course\": \"data-engineering-zoomcamp\"\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"It is an internet connectivity error, terraform is somehow not able to access the online registry. Check your VPN/Firewall settings (or just clear cookies or restart your network). Try terraform init again after this, it should work.\",\n",
       "    \"section\": \"Module 1: Docker and Terraform\",\n",
       "    \"question\": \"Terraform - Error: Failed to query available provider packages \\u2502 Could not retrieve the list of available versions for provider hashicorp/google: could not query \\u2502 provider registry for registry.terrafogorm.io/hashicorp/google: the request failed after 2 attempts, \\u2502 please try again later\",\n",
       "    \"course\": \"data-engineering-zoomcamp\"\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"The issue was with the network. Google is not accessible in my country, I am using a VPN. And The terminal program does not automatically follow the system proxy and requires separate proxy configuration settings.I opened a Enhanced Mode in Clash, which is a VPN app, and 'terraform apply' works! So if you encounter the same issue, you can ask help for your vpn provider.\",\n",
       "    \"section\": \"Module 1: Docker and Terraform\",\n",
       "    \"question\": \"Terraform - Error:Post \\\"https://storage.googleapis.com/storage/v1/b?alt=json&prettyPrint=false&project=coherent-ascent-379901\\\": oauth2: cannot fetch token: Post \\\"https://oauth2.googleapis.com/token\\\": dial tcp 172.217.163.42:443: i/o timeout\",\n",
       "    \"course\": \"data-engineering-zoomcamp\"\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"When running\\nterraform apply\\non wsl2 I've got this error:\\n\\u2502 Error: Post \\\"https://storage.googleapis.com/storage/v1/b?alt=json&prettyPrint=false&project=&lt;your-project-id&gt;\\\": oauth2: cannot fetch token: 400 Bad Request\\n\\u2502 Response: {\\\"error\\\":\\\"invalid_grant\\\",\\\"error_description\\\":\\\"Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.\\\"}\\nIT happens because there may be time desync on your machine which affects computing JWT\\nTo fix this, run the command\\nsudo hwclock -s\\nwhich fixes your system time.\\nReference\",\n",
       "    \"section\": \"Module 1: Docker and Terraform\",\n",
       "    \"question\": \"Terraform - Error 400 Bad Request.  Invalid JWT Token  on WSL.\",\n",
       "    \"course\": \"data-engineering-zoomcamp\"\n",
       "  }\n",
       "]</pre>\n",
       "            </div>\n",
       "\n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Response received\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\":\"Module 1 Docker and Terraform study t...)</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"query\":\"Module 1 Docker and Terraform study tips\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>[\n",
       "  {\n",
       "    \"text\": \"You get this error because I run the command terraform init outside the working directory, and this is wrong.You need first to navigate to the working directory that contains terraform configuration files, and and then run the command.\",\n",
       "    \"section\": \"Module 1: Docker and Terraform\",\n",
       "    \"question\": \"Terraform - Terraform initialized in an empty directory! The directory has no Terraform configuration files. You may begin working with Terraform immediately by creating Terraform configuration files.g\",\n",
       "    \"course\": \"data-engineering-zoomcamp\"\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"The error:\\nError: googleapi: Error 403: terraform-trans-campus@trans-campus-410115.iam.gserviceaccount.com does not have storage.buckets.create access to the Google Cloud project. Permission 'storage.buckets.create' denied on resource (or it may not exist)., forbidden\\nThe solution:\\nYou have to declare the project name as your Project ID, and not your Project name, available on GCP console Dashboard.\",\n",
       "    \"section\": \"Module 1: Docker and Terraform\",\n",
       "    \"question\": \"Terraform - Error creating Bucket: googleapi: Error 403: Permission denied to access \\u2018storage.buckets.create\\u2019\",\n",
       "    \"course\": \"data-engineering-zoomcamp\"\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"It is an internet connectivity error, terraform is somehow not able to access the online registry. Check your VPN/Firewall settings (or just clear cookies or restart your network). Try terraform init again after this, it should work.\",\n",
       "    \"section\": \"Module 1: Docker and Terraform\",\n",
       "    \"question\": \"Terraform - Error: Failed to query available provider packages \\u2502 Could not retrieve the list of available versions for provider hashicorp/google: could not query \\u2502 provider registry for registry.terrafogorm.io/hashicorp/google: the request failed after 2 attempts, \\u2502 please try again later\",\n",
       "    \"course\": \"data-engineering-zoomcamp\"\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"The issue was with the network. Google is not accessible in my country, I am using a VPN. And The terminal program does not automatically follow the system proxy and requires separate proxy configuration settings.I opened a Enhanced Mode in Clash, which is a VPN app, and 'terraform apply' works! So if you encounter the same issue, you can ask help for your vpn provider.\",\n",
       "    \"section\": \"Module 1: Docker and Terraform\",\n",
       "    \"question\": \"Terraform - Error:Post \\\"https://storage.googleapis.com/storage/v1/b?alt=json&prettyPrint=false&project=coherent-ascent-379901\\\": oauth2: cannot fetch token: Post \\\"https://oauth2.googleapis.com/token\\\": dial tcp 172.217.163.42:443: i/o timeout\",\n",
       "    \"course\": \"data-engineering-zoomcamp\"\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"When running\\nterraform apply\\non wsl2 I've got this error:\\n\\u2502 Error: Post \\\"https://storage.googleapis.com/storage/v1/b?alt=json&prettyPrint=false&project=&lt;your-project-id&gt;\\\": oauth2: cannot fetch token: 400 Bad Request\\n\\u2502 Response: {\\\"error\\\":\\\"invalid_grant\\\",\\\"error_description\\\":\\\"Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.\\\"}\\nIT happens because there may be time desync on your machine which affects computing JWT\\nTo fix this, run the command\\nsudo hwclock -s\\nwhich fixes your system time.\\nReference\",\n",
       "    \"section\": \"Module 1: Docker and Terraform\",\n",
       "    \"question\": \"Terraform - Error 400 Bad Request.  Invalid JWT Token  on WSL.\",\n",
       "    \"course\": \"data-engineering-zoomcamp\"\n",
       "  }\n",
       "]</pre>\n",
       "            </div>\n",
       "\n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Response received\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>To do well in Module 1, which focuses on Docker and Terraform, consider the following key strategies and tips:</p>\n",
       "<ol>\n",
       "<li><p><strong>Understand the Basics</strong>: Familiarize yourself with Docker and Terraform concepts. Know how containerization works with Docker, and how infrastructure as code is implemented with Terraform.</p>\n",
       "</li>\n",
       "<li><p><strong>Practice Using Commands</strong>: Execute commands like <code>terraform init</code> and <code>terraform apply</code> within the appropriate working directories. Make sure you are in the directory containing Terraform configuration files to avoid errors.</p>\n",
       "</li>\n",
       "<li><p><strong>Permissions and Access</strong>: Ensure you have the necessary permissions in Google Cloud if you are using any cloud resources. For example, you might need to declare the correct Project ID as opposed to your Project name.</p>\n",
       "</li>\n",
       "<li><p><strong>Connectivity Issues</strong>: If you experience issues accessing online registries, check your internet connection and firewall settings. Sometimes, VPN configurations may interfere with your Terraform commands.</p>\n",
       "</li>\n",
       "<li><p><strong>Error Resolution</strong>: Be aware of common errors such as &quot;ModuleNotFoundError&quot; for libraries and ensure the correct installation of dependencies. For instance, if you encounter a JWT-related error, you may need to synchronize your system time.</p>\n",
       "</li>\n",
       "<li><p><strong>Engage with the Community</strong>: Utilize forums, discussion groups, and any provided resources from the course. Seeking help from peers or instructors can also enhance your understanding.</p>\n",
       "</li>\n",
       "<li><p><strong>Hands-On Practice</strong>: The more you practice with the tools, the more proficient you'll become. Set up small projects to test out different aspects of Docker and Terraform.</p>\n",
       "</li>\n",
       "</ol>\n",
       "<p>By focusing on these areas, you'll be better equipped to succeed in Module 1.</p>\n",
       "<p><strong>Clarifying Question</strong>: Are there specific topics in Module 1 that you would like to explore further or any challenges you're facing?</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: DOCKER\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Response received\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>To excel specifically in the Docker aspects of Module 1, here are some focused tips and strategies:</p>\n",
       "<ol>\n",
       "<li><p><strong>Understand Docker Concepts</strong>: Familiarize yourself with core concepts such as images, containers, Dockerfile, and Docker Compose. Knowing how these work together is crucial for effective use.</p>\n",
       "</li>\n",
       "<li><p><strong>Installation and Setup</strong>: Ensure that Docker is correctly installed on your machine. Familiarize yourself with the command-line interface (CLI) commands such as <code>docker run</code>, <code>docker build</code>, <code>docker images</code>, and <code>docker ps</code>.</p>\n",
       "</li>\n",
       "<li><p><strong>Dockerfile Creation</strong>: Practice writing Dockerfiles. Understand how to define a basic Dockerfile with essential commands like <code>FROM</code>, <code>COPY</code>, <code>RUN</code>, and <code>CMD</code>. This is fundamental for building your custom images.</p>\n",
       "</li>\n",
       "<li><p><strong>Networking and Volumes</strong>: Learn about Docker networking to allow communication between containers. Also, understanding volumes for data persistence will help you manage your data effectively.</p>\n",
       "</li>\n",
       "<li><p><strong>Docker Compose</strong>: Explore how to use Docker Compose to define and run multi-container applications. Familiarize yourself with <code>docker-compose.yml</code> files and essential commands like <code>docker-compose up</code> and <code>docker-compose down</code>.</p>\n",
       "</li>\n",
       "<li><p><strong>Error Troubleshooting</strong>: Be prepared for common Docker errors. For example, if you encounter issues with building images or running containers, check the logs and error messages for guidance.</p>\n",
       "</li>\n",
       "<li><p><strong>Hands-On Projects</strong>: Implement small projects or exercises that require you to create Docker containers. This can be as simple as containerizing an application and ensuring it runs properly.</p>\n",
       "</li>\n",
       "<li><p><strong>Use Resources</strong>: Make use of official Docker documentation and community forums to understand best practices and troubleshooting tips.</p>\n",
       "</li>\n",
       "</ol>\n",
       "<p>By immersing yourself in these areas, you'll build a strong foundation in Docker, which is essential for success in Module 1.</p>\n",
       "<p><strong>Follow-Up Question</strong>: Is there a particular aspect of Docker that you‚Äôre finding challenging or need more information about?</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: add this back tO FAQ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Response received\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>add_entry({\"question\":\"How do I do well in Docker during ...)</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"question\":\"How do I do well in Docker during Module 1?\",\"answer\":\"1. **Understand Docker Concepts**: Familiarize yourself with core concepts such as images, containers, Dockerfile, and Docker Compose. Knowing how these work together is crucial for effective use.  \\n2. **Installation and Setup**: Ensure that Docker is correctly installed on your machine. Familiarize yourself with the command-line interface (CLI) commands such as `docker run`, `docker build`, `docker images`, and `docker ps`.  \\n3. **Dockerfile Creation**: Practice writing Dockerfiles. Understand how to define a basic Dockerfile with essential commands like `FROM`, `COPY`, `RUN`, and `CMD`. This is fundamental for building your custom images.  \\n4. **Networking and Volumes**: Learn about Docker networking to allow communication between containers. Also, understanding volumes for data persistence will help you manage your data effectively.  \\n5. **Docker Compose**: Explore how to use Docker Compose to define and run multi-container applications. Familiarize yourself with `docker-compose.yml` files and essential commands like `docker-compose up` and `docker-compose down`.  \\n6. **Error Troubleshooting**: Be prepared for common Docker errors. For example, if you encounter issues with building images or running containers, check the logs and error messages for guidance.  \\n7. **Hands-On Projects**: Implement small projects or exercises that require you to create Docker containers. This can be as simple as containerizing an application and ensuring it runs properly.  \\n8. **Use Resources**: Make use of official Docker documentation and community forums to understand best practices and troubleshooting tips.\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>null</pre>\n",
       "            </div>\n",
       "\n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Response received\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>I've added the advice for excelling in Docker during Module 1 to the FAQ. If you have any more questions or need further assistance, feel free to ask! Are there other topics you would like to explore?</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: STOP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "result = runner.run();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d61ccc14-22c2-4d56-9dbe-6cddbe647296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CostInfo(input_cost=Decimal('0.00102285'), output_cost=Decimal('0.0003576'), total_cost=Decimal('0.00138045'))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfd3cec-e86f-4960-ad0a-7ef15897d72e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "910ab18e-99b1-4cae-b80e-85443632af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5b6e11c3-ea57-484c-881f-c78154c53430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.search(query: str) -> List[Dict[str, Any]]>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "00dc4db0-8c6a-4a00-8763-94ed9d65b7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_agent = Agent(\n",
    "    name='search',\n",
    "    model='openai:gpt-4o-mini',\n",
    "    instructions=agent_instructions,\n",
    "    tools=[search, add_entry],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "16a81cec-1adf-41c1-a567-9ead802bd730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object AbstractAgent.run at 0x72b9bed772a0>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_agent.run(user_prompt=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6dc285b8-4391-421f-9500-25a8180f5d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " HOW DO I DO WELL IN MODULE 2?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration_nmber=1\n",
      "To do well in Module 2 of the Data Engineering Zoomcamp, here are some tips based on experiences from other students and general best practices:\n",
      "\n",
      "1. **Understand Workflow Orchestration**: This module focuses heavily on workflow orchestration tools. Familiarize yourself with tools like Apache Airflow and how to implement workflows effectively.\n",
      "\n",
      "2. **Engage with the Course Materials**: Make sure to review all provided materials, including lectures and documentation. Pay attention to any hands-on exercises, as these will solidify your understanding.\n",
      "\n",
      "3. **Practice with Git and Version Control**: The module includes tasks that require using Git. Make sure you understand basic commands for version control, as working with repositories is essential.\n",
      "\n",
      "4. **Utilize Resources**: Utilize Slack channels or forums to ask questions and share insights with classmates. This communal learning can provide new perspectives and solutions to problems.\n",
      "\n",
      "5. **Hands-on Experience**: Work on exercises and the demo pipelines. Apply what you learn in practical scenarios, which will help in retaining information and understanding its application.\n",
      "\n",
      "6. **Manage Your GitHub Repositories**: If you downloaded the Mage repository, ensure you properly integrate its files into your personal GitHub for the course. Following the steps shared by other students on how to include these files can be very helpful.\n",
      "\n",
      "7. **Be Analytical**: If you encounter issues or errors (like permission issues when building Docker images), take the time to analyze the problem carefully and understand the underlying cause.\n",
      "\n",
      "By following these strategies and fully engaging with the learning materials and community, you're on a solid path to success in Module 2.\n",
      "\n",
      "Do you have any specific areas within Module 2 that you find particularly challenging or would like to explore further?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ADD THIS TO FAQ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration_nmber=2\n",
      "The information has been successfully added to the FAQ section. If you have any more questions or need assistance with other topics, feel free to ask!\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " STOP\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "\n",
    "iteration_nmber = 0\n",
    "\n",
    "while True:\n",
    "    user_prompt = input()\n",
    "    if user_prompt.strip().lower() == 'stop': \n",
    "        break\n",
    "\n",
    "    result = await search_agent.run(\n",
    "        user_prompt=user_prompt,\n",
    "        message_history=messages,\n",
    "\n",
    "    )\n",
    "\n",
    "    iteration_nmber = iteration_nmber + 1\n",
    "    print(f'{iteration_nmber=}')\n",
    "    print(result.output)\n",
    "    print()\n",
    "\n",
    "    messages.extend(result.new_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "19404d9f-5a34-4b15-a325-84223bc03199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModelRequest(parts=[UserPromptPart(content='HOW DO I DO WELL IN MODULE 2?', timestamp=datetime.datetime(2025, 11, 25, 11, 23, 57, 792107, tzinfo=datetime.timezone.utc))], instructions=\"You're a course teaching assistant. \\nYou're given a question from a course student and your task is to answer it.\\n\\nIf you want to look up the answer, explain why before making the call. Use as many \\nkeywords from the user question as possible when making first requests.\\n\\nMake multiple searches (up to 3).\\n\\nAt the end, make a clarifying question based on what you presented and ask if there are \\nother areas that the user wants to explore.\", run_id='128bbbb7-51f6-4dfe-92d3-321eecb76990'),\n",
       " ModelResponse(parts=[ToolCallPart(tool_name='search', args='{\"query\":\"how to do well in module 2\"}', tool_call_id='call_5IGF82ad7pbUKlHlSiHzRoSR')], usage=RequestUsage(input_tokens=325, output_tokens=20, details={'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}), model_name='gpt-4o-mini-2024-07-18', timestamp=datetime.datetime(2025, 11, 25, 11, 23, 57, tzinfo=TzInfo(0)), provider_name='openai', provider_details={'finish_reason': 'tool_calls'}, provider_response_id='chatcmpl-CflRFIRXNCnm7gVDWE6ZhcZRS5WR3', finish_reason='tool_call', run_id='128bbbb7-51f6-4dfe-92d3-321eecb76990'),\n",
       " ModelRequest(parts=[ToolReturnPart(tool_name='search', content=[{'question': 'How do I do well in Docker during Module 1?', 'text': '1. **Understand Docker Concepts**: Familiarize yourself with core concepts such as images, containers, Dockerfile, and Docker Compose. Knowing how these work together is crucial for effective use.  \\n2. **Installation and Setup**: Ensure that Docker is correctly installed on your machine. Familiarize yourself with the command-line interface (CLI) commands such as `docker run`, `docker build`, `docker images`, and `docker ps`.  \\n3. **Dockerfile Creation**: Practice writing Dockerfiles. Understand how to define a basic Dockerfile with essential commands like `FROM`, `COPY`, `RUN`, and `CMD`. This is fundamental for building your custom images.  \\n4. **Networking and Volumes**: Learn about Docker networking to allow communication between containers. Also, understanding volumes for data persistence will help you manage your data effectively.  \\n5. **Docker Compose**: Explore how to use Docker Compose to define and run multi-container applications. Familiarize yourself with `docker-compose.yml` files and essential commands like `docker-compose up` and `docker-compose down`.  \\n6. **Error Troubleshooting**: Be prepared for common Docker errors. For example, if you encounter issues with building images or running containers, check the logs and error messages for guidance.  \\n7. **Hands-On Projects**: Implement small projects or exercises that require you to create Docker containers. This can be as simple as containerizing an application and ensuring it runs properly.  \\n8. **Use Resources**: Make use of official Docker documentation and community forums to understand best practices and troubleshooting tips.', 'section': 'user added', 'course': 'data-engineering-zoomcamp'}, {'text': 'Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\\nKrishna Anand', 'section': 'Module 5: pyspark', 'question': 'Module Not Found Error in Jupyter Notebook .', 'course': 'data-engineering-zoomcamp'}, {'text': 'You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=‚Äù${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}‚Äù\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\\nAdditionally, you can check for the version of ‚Äòpy4j‚Äô of the spark you‚Äôre using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.', 'section': 'Module 5: pyspark', 'question': \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\", 'course': 'data-engineering-zoomcamp'}, {'text': \"Issue:\\ne‚Ä¶\\nSolution:\\npip install psycopg2-binary\\nIf you already have it, you might need to update it:\\npip install psycopg2-binary --upgrade\\nOther methods, if the above fails:\\nif you are getting the ‚Äú ModuleNotFoundError: No module named 'psycopg2' ‚Äú error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\nFirst uninstall the psycopg package\\nThen update conda or pip\\nThen install psycopg again using pip.\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\", 'section': 'Module 1: Docker and Terraform', 'question': \"Postgres - ModuleNotFoundError: No module named 'psycopg2'\", 'course': 'data-engineering-zoomcamp'}, {'text': \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\", 'section': 'Module 4: analytics engineering with dbt', 'question': \"DBT - Error: No module named 'pytz' while setting up dbt with docker\", 'course': 'data-engineering-zoomcamp'}], tool_call_id='call_5IGF82ad7pbUKlHlSiHzRoSR', timestamp=datetime.datetime(2025, 11, 25, 11, 23, 59, 587017, tzinfo=datetime.timezone.utc))], instructions=\"You're a course teaching assistant. \\nYou're given a question from a course student and your task is to answer it.\\n\\nIf you want to look up the answer, explain why before making the call. Use as many \\nkeywords from the user question as possible when making first requests.\\n\\nMake multiple searches (up to 3).\\n\\nAt the end, make a clarifying question based on what you presented and ask if there are \\nother areas that the user wants to explore.\", run_id='128bbbb7-51f6-4dfe-92d3-321eecb76990'),\n",
       " ModelResponse(parts=[ToolCallPart(tool_name='search', args='{\"query\":\"tips for succeeding in Module 2 data engineering zoomcamp\"}', tool_call_id='call_sdgmpsG3RJ0wixKgo8QhXsG3')], usage=RequestUsage(input_tokens=1622, output_tokens=23, details={'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}), model_name='gpt-4o-mini-2024-07-18', timestamp=datetime.datetime(2025, 11, 25, 11, 23, 59, tzinfo=TzInfo(0)), provider_name='openai', provider_details={'finish_reason': 'tool_calls'}, provider_response_id='chatcmpl-CflRHlmvRCaNwQeyZom8iFdGCQ28C', finish_reason='tool_call', run_id='128bbbb7-51f6-4dfe-92d3-321eecb76990'),\n",
       " ModelRequest(parts=[ToolReturnPart(tool_name='search', content=[{'text': 'Copy the file found in the Java example: data-engineering-zoomcamp/week_6_stream_processing/java/kafka_examples/src/main/resources/rides.csv', 'section': 'Module 6: streaming with kafka', 'question': 'data-engineering-zoomcamp/week_6_stream_processing/python/resources/rides.csv is missing', 'course': 'data-engineering-zoomcamp'}, {'text': 'Assuming you downloaded the Mage repo in the week 2 folder of the Data Engineering Zoomcamp, you might want to include your mage copy, demo pipelines and homework within your personal copy of the Data Engineering Zoomcamp repo. This will not work by default, because GitHub sees them as two separate repositories, and one does not track the other. To add the Mage files to your main DE Zoomcamp repo, you will need to:\\nMove the contents of the .gitignore file in your main .gitignore.\\nUse the terminal to cd into the Mage folder and:\\nrun ‚Äúgit remote remove origin‚Äù to de-couple the Mage repo,\\nrun ‚Äúrm -rf .git‚Äù to delete local git files,\\nrun ‚Äúgit add .‚Äù to add the current folder as changes to stage, commit and push.', 'section': 'Module 2: Workflow Orchestration', 'question': 'Git - How do I include the files in the Mage repo (including exercise files and homework) in a personal copy of the Data Engineering Zoomcamp repo?', 'course': 'data-engineering-zoomcamp'}, {'text': 'This error appeared when running the command: docker build -t taxi_ingest:v001 .\\nWhen feeding the database with the data the user id of the directory ny_taxi_postgres_data was changed to 999, so my user couldn‚Äôt access it when running the above command. Even though this is not the problem here it helped to raise the error due to the permission issue.\\nSince at this point we only need the files Dockerfile and ingest_data.py, to fix this error one can run the docker build command on a different directory (having only these two files).\\nA more complete explanation can be found here: https://stackoverflow.com/questions/41286028/docker-build-error-checking-context-cant-stat-c-users-username-appdata\\nYou can fix the problem by changing the permission of the directory on ubuntu with following command:\\nsudo chown -R $USER dir_path\\nOn windows follow the link: https://thegeekpage.com/take-ownership-of-a-file-folder-through-command-prompt-in-windows-10/ \\n\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tAdded by\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tKenan Arslanbay', 'section': 'Module 1: Docker and Terraform', 'question': \"Docker - build error: error checking context: 'can't stat '/home/user/repos/data-engineering/week_1_basics_n_setup/2_docker_sql/ny_taxi_postgres_data''.\", 'course': 'data-engineering-zoomcamp'}, {'text': 'I initially followed data-engineering-zoomcamp/03-data-warehouse/extras/web_to_gcs.py at main ¬∑ DataTalksClub/data-engineering-bootcamp (github.com)\\nBut it was taking forever for the yellow trip data and when I tried to download and upload the parquet files directly to GCS, that works fine but when creating the Bigquery table, there was a schema inconsistency issue\\nThen I found another hack shared in the slack which was suggested by Victoria.\\n[Optional] Hack for loading data to BigQuery for Week 4 - YouTube\\nPlease watch until the end as there is few schema changes required to be done', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Hack to load yellow and green trip data for 2019 and 2020', 'course': 'data-engineering-zoomcamp'}, {'text': \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\", 'section': 'Module 4: analytics engineering with dbt', 'question': \"DBT - Error: No module named 'pytz' while setting up dbt with docker\", 'course': 'data-engineering-zoomcamp'}], tool_call_id='call_sdgmpsG3RJ0wixKgo8QhXsG3', timestamp=datetime.datetime(2025, 11, 25, 11, 24, 0, 643659, tzinfo=datetime.timezone.utc))], instructions=\"You're a course teaching assistant. \\nYou're given a question from a course student and your task is to answer it.\\n\\nIf you want to look up the answer, explain why before making the call. Use as many \\nkeywords from the user question as possible when making first requests.\\n\\nMake multiple searches (up to 3).\\n\\nAt the end, make a clarifying question based on what you presented and ask if there are \\nother areas that the user wants to explore.\", run_id='128bbbb7-51f6-4dfe-92d3-321eecb76990'),\n",
       " ModelResponse(parts=[ToolCallPart(tool_name='search', args='{\"query\":\"success in Module 2 tips data engineering zoomcamp\"}', tool_call_id='call_HTciPDJ4ESkWPLVYktzu7l9Q')], usage=RequestUsage(input_tokens=2579, cache_read_tokens=1536, output_tokens=22, details={'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}), model_name='gpt-4o-mini-2024-07-18', timestamp=datetime.datetime(2025, 11, 25, 11, 24, tzinfo=TzInfo(0)), provider_name='openai', provider_details={'finish_reason': 'tool_calls'}, provider_response_id='chatcmpl-CflRIcGJebPT7T1mq4d5fn22YoLup', finish_reason='tool_call', run_id='128bbbb7-51f6-4dfe-92d3-321eecb76990'),\n",
       " ModelRequest(parts=[ToolReturnPart(tool_name='search', content=[{'text': 'Copy the file found in the Java example: data-engineering-zoomcamp/week_6_stream_processing/java/kafka_examples/src/main/resources/rides.csv', 'section': 'Module 6: streaming with kafka', 'question': 'data-engineering-zoomcamp/week_6_stream_processing/python/resources/rides.csv is missing', 'course': 'data-engineering-zoomcamp'}, {'text': 'Assuming you downloaded the Mage repo in the week 2 folder of the Data Engineering Zoomcamp, you might want to include your mage copy, demo pipelines and homework within your personal copy of the Data Engineering Zoomcamp repo. This will not work by default, because GitHub sees them as two separate repositories, and one does not track the other. To add the Mage files to your main DE Zoomcamp repo, you will need to:\\nMove the contents of the .gitignore file in your main .gitignore.\\nUse the terminal to cd into the Mage folder and:\\nrun ‚Äúgit remote remove origin‚Äù to de-couple the Mage repo,\\nrun ‚Äúrm -rf .git‚Äù to delete local git files,\\nrun ‚Äúgit add .‚Äù to add the current folder as changes to stage, commit and push.', 'section': 'Module 2: Workflow Orchestration', 'question': 'Git - How do I include the files in the Mage repo (including exercise files and homework) in a personal copy of the Data Engineering Zoomcamp repo?', 'course': 'data-engineering-zoomcamp'}, {'text': 'This error appeared when running the command: docker build -t taxi_ingest:v001 .\\nWhen feeding the database with the data the user id of the directory ny_taxi_postgres_data was changed to 999, so my user couldn‚Äôt access it when running the above command. Even though this is not the problem here it helped to raise the error due to the permission issue.\\nSince at this point we only need the files Dockerfile and ingest_data.py, to fix this error one can run the docker build command on a different directory (having only these two files).\\nA more complete explanation can be found here: https://stackoverflow.com/questions/41286028/docker-build-error-checking-context-cant-stat-c-users-username-appdata\\nYou can fix the problem by changing the permission of the directory on ubuntu with following command:\\nsudo chown -R $USER dir_path\\nOn windows follow the link: https://thegeekpage.com/take-ownership-of-a-file-folder-through-command-prompt-in-windows-10/ \\n\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tAdded by\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tKenan Arslanbay', 'section': 'Module 1: Docker and Terraform', 'question': \"Docker - build error: error checking context: 'can't stat '/home/user/repos/data-engineering/week_1_basics_n_setup/2_docker_sql/ny_taxi_postgres_data''.\", 'course': 'data-engineering-zoomcamp'}, {'text': \"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\", 'section': 'General course-related questions', 'question': 'Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?', 'course': 'data-engineering-zoomcamp'}, {'text': 'I initially followed data-engineering-zoomcamp/03-data-warehouse/extras/web_to_gcs.py at main ¬∑ DataTalksClub/data-engineering-bootcamp (github.com)\\nBut it was taking forever for the yellow trip data and when I tried to download and upload the parquet files directly to GCS, that works fine but when creating the Bigquery table, there was a schema inconsistency issue\\nThen I found another hack shared in the slack which was suggested by Victoria.\\n[Optional] Hack for loading data to BigQuery for Week 4 - YouTube\\nPlease watch until the end as there is few schema changes required to be done', 'section': 'Module 4: analytics engineering with dbt', 'question': 'Hack to load yellow and green trip data for 2019 and 2020', 'course': 'data-engineering-zoomcamp'}], tool_call_id='call_HTciPDJ4ESkWPLVYktzu7l9Q', timestamp=datetime.datetime(2025, 11, 25, 11, 24, 1, 701205, tzinfo=datetime.timezone.utc))], instructions=\"You're a course teaching assistant. \\nYou're given a question from a course student and your task is to answer it.\\n\\nIf you want to look up the answer, explain why before making the call. Use as many \\nkeywords from the user question as possible when making first requests.\\n\\nMake multiple searches (up to 3).\\n\\nAt the end, make a clarifying question based on what you presented and ask if there are \\nother areas that the user wants to explore.\", run_id='128bbbb7-51f6-4dfe-92d3-321eecb76990'),\n",
       " ModelResponse(parts=[TextPart(content=\"To do well in Module 2 of the Data Engineering Zoomcamp, here are some tips based on experiences from other students and general best practices:\\n\\n1. **Understand Workflow Orchestration**: This module focuses heavily on workflow orchestration tools. Familiarize yourself with tools like Apache Airflow and how to implement workflows effectively.\\n\\n2. **Engage with the Course Materials**: Make sure to review all provided materials, including lectures and documentation. Pay attention to any hands-on exercises, as these will solidify your understanding.\\n\\n3. **Practice with Git and Version Control**: The module includes tasks that require using Git. Make sure you understand basic commands for version control, as working with repositories is essential.\\n\\n4. **Utilize Resources**: Utilize Slack channels or forums to ask questions and share insights with classmates. This communal learning can provide new perspectives and solutions to problems.\\n\\n5. **Hands-on Experience**: Work on exercises and the demo pipelines. Apply what you learn in practical scenarios, which will help in retaining information and understanding its application.\\n\\n6. **Manage Your GitHub Repositories**: If you downloaded the Mage repository, ensure you properly integrate its files into your personal GitHub for the course. Following the steps shared by other students on how to include these files can be very helpful.\\n\\n7. **Be Analytical**: If you encounter issues or errors (like permission issues when building Docker images), take the time to analyze the problem carefully and understand the underlying cause.\\n\\nBy following these strategies and fully engaging with the learning materials and community, you're on a solid path to success in Module 2.\\n\\nDo you have any specific areas within Module 2 that you find particularly challenging or would like to explore further?\")], usage=RequestUsage(input_tokens=3477, cache_read_tokens=2560, output_tokens=347, details={'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}), model_name='gpt-4o-mini-2024-07-18', timestamp=datetime.datetime(2025, 11, 25, 11, 24, 1, tzinfo=TzInfo(0)), provider_name='openai', provider_details={'finish_reason': 'stop'}, provider_response_id='chatcmpl-CflRJjMh5j4jbiZHkdeb1b50e5mJ9', finish_reason='stop', run_id='128bbbb7-51f6-4dfe-92d3-321eecb76990'),\n",
       " ModelRequest(parts=[UserPromptPart(content='ADD THIS TO FAQ', timestamp=datetime.datetime(2025, 11, 25, 11, 24, 19, 736314, tzinfo=datetime.timezone.utc))], instructions=\"You're a course teaching assistant. \\nYou're given a question from a course student and your task is to answer it.\\n\\nIf you want to look up the answer, explain why before making the call. Use as many \\nkeywords from the user question as possible when making first requests.\\n\\nMake multiple searches (up to 3).\\n\\nAt the end, make a clarifying question based on what you presented and ask if there are \\nother areas that the user wants to explore.\", run_id='9ebc2d12-7e81-4af1-ae04-5926820efd55'),\n",
       " ModelResponse(parts=[ToolCallPart(tool_name='add_entry', args='{\"question\":\"How do I do well in Module 2 of the Data Engineering Zoomcamp?\",\"answer\":\"To do well in Module 2 of the Data Engineering Zoomcamp, here are some tips based on experiences from other students and general best practices:\\\\n\\\\n1. **Understand Workflow Orchestration**: This module focuses heavily on workflow orchestration tools. Familiarize yourself with tools like Apache Airflow and how to implement workflows effectively.\\\\n\\\\n2. **Engage with the Course Materials**: Make sure to review all provided materials, including lectures and documentation. Pay attention to any hands-on exercises, as these will solidify your understanding.\\\\n\\\\n3. **Practice with Git and Version Control**: The module includes tasks that require using Git. Make sure you understand basic commands for version control, as working with repositories is essential.\\\\n\\\\n4. **Utilize Resources**: Utilize Slack channels or forums to ask questions and share insights with classmates. This communal learning can provide new perspectives and solutions to problems.\\\\n\\\\n5. **Hands-on Experience**: Work on exercises and the demo pipelines. Apply what you learn in practical scenarios, which will help in retaining information and understanding its application.\\\\n\\\\n6. **Manage Your GitHub Repositories**: If you downloaded the Mage repository, ensure you properly integrate its files into your personal GitHub for the course. Following the steps shared by other students on how to include these files can be very helpful.\\\\n\\\\n7. **Be Analytical**: If you encounter issues or errors (like permission issues when building Docker images), take the time to analyze the problem carefully and understand the underlying cause.\\\\n\\\\nBy following these strategies and fully engaging with the learning materials and community, you\\'re on a solid path to success in Module 2.\"}', tool_call_id='call_PehA2jRozrE7W3PomqamWoMa')], usage=RequestUsage(input_tokens=3835, cache_read_tokens=3712, output_tokens=372, details={'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}), model_name='gpt-4o-mini-2024-07-18', timestamp=datetime.datetime(2025, 11, 25, 11, 24, 19, tzinfo=TzInfo(0)), provider_name='openai', provider_details={'finish_reason': 'tool_calls'}, provider_response_id='chatcmpl-CflRbR7K9V3TwrG4TrNnj3KrEjZ4x', finish_reason='tool_call', run_id='9ebc2d12-7e81-4af1-ae04-5926820efd55'),\n",
       " ModelRequest(parts=[ToolReturnPart(tool_name='add_entry', content=None, tool_call_id='call_PehA2jRozrE7W3PomqamWoMa', timestamp=datetime.datetime(2025, 11, 25, 11, 24, 31, 692147, tzinfo=datetime.timezone.utc))], instructions=\"You're a course teaching assistant. \\nYou're given a question from a course student and your task is to answer it.\\n\\nIf you want to look up the answer, explain why before making the call. Use as many \\nkeywords from the user question as possible when making first requests.\\n\\nMake multiple searches (up to 3).\\n\\nAt the end, make a clarifying question based on what you presented and ask if there are \\nother areas that the user wants to explore.\", run_id='9ebc2d12-7e81-4af1-ae04-5926820efd55'),\n",
       " ModelResponse(parts=[TextPart(content='The information has been successfully added to the FAQ section. If you have any more questions or need assistance with other topics, feel free to ask!')], usage=RequestUsage(input_tokens=4216, cache_read_tokens=4096, output_tokens=30, details={'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}), model_name='gpt-4o-mini-2024-07-18', timestamp=datetime.datetime(2025, 11, 25, 11, 24, 31, tzinfo=TzInfo(0)), provider_name='openai', provider_details={'finish_reason': 'stop'}, provider_response_id='chatcmpl-CflRnjSBjW1Fib7GrJffB7I3D49xj', finish_reason='stop', run_id='9ebc2d12-7e81-4af1-ae04-5926820efd55')]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.all_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b14a82-56a6-4a80-b375-e8a3f0bbb1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8f033553-a196-4148-bfcd-63138ce6c3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decimal('0.00091575')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = calc_price(\n",
    "    result.usage(),\n",
    "    model_ref='gpt-4o-mini',\n",
    "    provider_id='openai'\n",
    ")\n",
    "price.total_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9cc17c-fe69-40ae-845c-c80cb5dc4dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6886352e-810c-4fba-9bf0-e60303b70406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toyaikit.chat.runners import PydanticAIRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8fbb49bf-91e3-4c2a-9293-26a67170648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyai_runner = PydanticAIRunner(\n",
    "    chat_interface=chat_interface,\n",
    "    agent=search_agent\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dc50ad-05c8-4b05-ac1e-96d5b1edbada",
   "metadata": {},
   "source": [
    "await pyai_runner.run();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8777644e-7498-4dd9-82a5-7a5bc7510714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.append.AppendableIndex at 0x72b9c18ead20>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5b25b52c-b8c5-4f4b-9788-a19458ea7ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import search_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "70308917-00a4-4435-b26f-ec61bf2af3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_search_tools = search_tools.SearchTools(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "6dd9a3ed-123f-4438-b98a-0088cf5f4d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toyaikit.tools import get_instance_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1ab20065-9c8c-469f-8204-243e26b0da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_agent = Agent(\n",
    "    name='search',\n",
    "    model='openai:gpt-4o-mini',\n",
    "    instructions=agent_instructions,\n",
    "    tools=get_instance_methods(agent_search_tools),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48f5817-1be2-4d38-b6d4-9cb6b964ac5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
